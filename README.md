# NKUST 類神經網路期末報告
**隊伍：TEAM_8944**

**隊員：[陳相圖](https://github.com/35783329jeff1122)、[吳澤延](https://github.com/Olive020)**

**Private leaderboard：0.947555 / Rank 104**

## 壹、資料處理與程式環境

### 一、資料前處理
在醫療影像分析任務中，資料的品質與多樣性直接決定了模型的泛化能力。本研究針對主動脈瓣（Aortic Valve）偵測任務，設計了一套結合「離線增強」與「線上增強」的混合處理流程。

首先，在離線處理階段，為解決醫療影像資料量通常較少的問題，我們對原始訓練集進行了幾何變換擴充。具體而言，將每張原始影像分別進行 0 度、90 度、180 度及 270 度的旋轉處理。此舉不僅將資料集規模擴充為原本的四倍，更重要的是賦予模型「旋轉不變性（Rotation Invariance）」，確保無論主動脈瓣在影像中呈現何種角度，模型皆能準確定位。此外，我們引入了雜訊注入技術以模擬真實臨床環境的干擾。透過加入模擬低光源熱雜訊的「高斯噪點（Gaussian Noise）」以及模擬訊號傳輸錯誤的「胡椒鹽噪點（Salt-and-Pepper Noise）」，迫使模型學習忽略細微的像素級干擾，專注於瓣膜的結構特徵，從而顯著提升模型在實際應用中的抗噪能力與強健性。

其次，在訓練期間的線上處理（On-the-fly Processing），我們採用了針對醫療影像優化的正規化流程。影像輸入模型前會統一調整尺寸（Resize）至 640x640 像素，並進行標準化（Normalization），將像素值映射至 [0, 1] 區間，以加速梯度下降的收斂過程。

### 二、原始程式碼概述
本專案的核心訓練腳本 `train_yolo_optimized.py` 是基於 Ultralytics YOLOv11 架構進行深度客製化開發。程式碼架構採用模組化設計，主要包含「配置管理」、「資料管線」、「模型訓練」與「推論評估」四大模組。

在配置管理方面，程式內建了多種訓練模式（如 `high_accuracy`, `balanced`, `ultra_fast_plus`），透過字典結構（Dictionary）動態管理超參數，讓開發者能透過命令列參數快速切換實驗設定。為了提升訓練穩定性，程式碼特別實作了「防 OOM（Out of Memory）機制」，透過偵測 `PYTORCH_CUDA_ALLOC_CONF` 環境變數並支援自動 Batch Size 調整（Auto-batch），有效解決了在有限顯存環境下訓練大型模型（如 YOLO11x）常遇到的記憶體溢出問題。此外，針對醫療影像特性，我們在程式碼中定義了專屬的 `AUGMENTATION_CONFIGS['medical']`，移除了 Mosaic 與 Mixup 等可能破壞解剖結構的合成類增強，僅保留幾何與亮度變換，這是本專案程式碼的一大特色。

### 三、執行環境
本研究的實驗環境建立於 Windows 11 作業系統之上。開發語言選用 Python 3.12，這是目前穩定且效能優異的版本。深度學習框架採用 PyTorch，並整合 Ultralytics 套件以實作最新的 YOLOv11 演算法。在資料處理方面，輔以 NumPy 進行高效能張量運算、Pandas 處理結構化數據，以及 OpenCV 進行影像的前處理與幾何變換。

在硬體加速配置上，本實驗設備具備高算力規格，使用 Intel Core i7-14700F 處理器處理資料載入與預處理，並搭載 NVIDIA GeForce RTX 4080 SUPER 顯示卡進行核心的卷積運算與反向傳播。系統配置 64GB DDR5 記憶體，確保在處理高解析度醫療影像與進行高強度模型訓練時，系統能維持高吞吐量與穩定性。此高規格硬體環境使我們能夠在有限的時間內完成多輪實驗迭代，最終收斂出高精度的偵測模型。

## 貳、模型設計與訓練策略

### 一、模型訓練與預測原始程式碼
**GitHub 連結：** https://github.com/Olive020/TEAM_8944
*(註：本連結包含完整的 `train_yolo_optimized.py`、環境設定檔 `requirements.txt` 以及推論腳本，並附有詳細 README 說明如何重現訓練結果。)*

### 二、說明
本研究採用「遷移學習（Transfer Learning）」策略。我們不從頭訓練模型，而是載入在 COCO 大型資料集上預訓練的 YOLOv11 權重（如 `yolo11n.pt` 或 `yolo11x.pt`）。這種策略讓模型在初始階段即具備邊緣檢測、紋理識別等底層視覺能力，隨後再針對主動脈瓣資料集進行微調（Fine-tuning）。

核心程式碼邏輯中，我們特別設計了「動態資料集載入」功能。程式會自動偵測現有的 `datasets/train` 與 `datasets/val` 目錄結構，並動態生成 YOLO 所需的 `.yaml` 設定檔，避免了繁瑣的手動路徑配置。在訓練迴圈中，系統監控驗證集損失（Validation Loss），並實作了早停機制（Early Stopping），若模型效能連續 60 個 Epoch 未提升，則自動終止訓練，這在防止過擬合（Overfitting）上扮演關鍵角色。

### 三、模型訓練流程
訓練流程共分為三個階段：
1.  **初始化與暖身（Warmup）：** 載入預訓練權重後，前 3 個 Epoch 進行暖身訓練。此階段使用較低的學習率與動量，讓模型參數緩慢適應新的資料分佈，避免梯度劇烈震盪導致訓練發散。
2.  **主訓練階段（Main Training）：** 採用 AdamW 優化器搭配餘弦退火（Cosine Annealing）學習率排程。我們經過多次實驗迭代（共計約 3000 epoch 的嘗試，包含不同參數組合），最終在決賽版本中採用 150 Epochs 的設定。在此階段，模型會學習主動脈瓣的特徵，並透過損失函數（包含 Box Loss, Class Loss, DFL Loss）不斷修正預測框的座標與類別機率。
3.  **驗證與保存（Validation & Save）：** 每個 Epoch 結束後，模型會對驗證集進行推論，計算 mAP50 與 mAP50-95 指標。系統會自動保存「最佳權重（best.pt）」與「最後權重（last.pt）」。最終提交的結果是基於驗證分數最高的權重進行測試集推論。

### 四、參數設定
為了在競賽中取得最佳成績，我們針對 `train_yolo_optimized.py` 中的 `ultra_fast_plus` 模式進行了精細的參數調校：
*   **Epochs (訓練輪數)：** 設定為 150。醫療影像特徵較為隱晦，較長的訓練週期有助於模型捕捉細微特徵。
*   **Batch Size (批次大小)：** 設定為 -1 (Auto)。程式自動計算顯示卡記憶體上限，最大化批次大小以穩定 Batch Normalization 的效果。
*   **Image Size (影像尺寸)：** 640 x 640。此尺寸在保留病灶細節與運算速度之間取得了最佳平衡。
*   **Optimizer (優化器)：** AdamW。相較於 SGD，AdamW 在處理稀疏梯度與雜訊較多的醫療資料時表現更佳。
*   **Learning Rate (學習率)：** 初始學習率 `lr0` 設為 0.001，並設定動量為 0.937，權重衰減（Weight Decay）為 0.0005 以抑制過擬合。
*   **Augmentation (增強參數)：** 採用客製化醫療參數：HSV 亮度變異 ±25%，平移 ±5%，縮放 ±15%，並**關閉** Mosaic 與 Mixup，確保影像的解剖結構不被合成演算法破壞。

## 參、分析與結論

### 模型成效分析
本團隊在本次競賽中取得了 Private Leaderboard 0.947555 的高分，排名第 104 名。此成績顯示我們所訓練的 YOLOv11 模型在主動脈瓣偵測任務上具有極高的準確度與可靠性。

分析其成功因素，主要歸功於以下三點：
1.  **先進的模型架構：** YOLOv11 引入了更高效的特徵提取模組（C3k2/C2f），相較於舊版 YOLOv5/v8，在處理小物件與模糊邊界（如心臟超音波或 CT 中的瓣膜邊緣）時，展現了更強的特徵聚合能力。
2.  **醫療專用的資料增強策略：** 這是本研究的關鍵突破點。一般的物件偵測任務常使用 Mosaic（馬賽克拼貼）來提升效能，但在醫療影像中，這種拼貼會破壞器官的相對位置與解剖邏輯。我們在程式碼中果斷移除了此類增強，轉而專注於亮度調整（模擬不同儀器的成像差異）與微幅幾何變換。實驗證明，這種「保守但精準」的增強策略顯著提升了模型在測試集上的表現。
3.  **穩健的訓練策略：** 透過 AdamW 優化器與 Cosine Annealing 學習率調度，模型能夠在訓練後期跳出局部最佳解（Local Minima），找到全域更佳的參數配置。

### 開源資源的影響
本專案高度依賴開源社群的貢獻。Ultralytics 提供的 YOLO 框架大幅降低了開發門檻，使我們能將時間專注於數據分析與參數調整，而非底層神經網路的刻畫。預訓練模型（Pre-trained Models）的使用更是關鍵，若無 COCO 資料集的預訓練權重，僅憑本次競賽提供的少量醫療影像，極難從零訓練出如此高精度的模型。這凸顯了「遷移學習」在現代醫療 AI 領域的重要性。

### 未來改進方向
儘管模型表現優異，但仍有改進空間：
1.  **測試時增強（Test Time Augmentation, TTA）：** 目前推論階段僅使用單張影像預測。未來可引入 TTA 技術，在推論時對同一張影像進行多角度預測並取平均，預期可進一步提升 0.5%~1% 的 mAP。
2.  **模型集成（Ensemble Learning）：** 本次主要提交單一模型結果。若能同時訓練 YOLO11x（大模型）與 YOLO11m（中模型），並將兩者的預測框進行加權融合（Weighted Box Fusion），應能有效減少誤判，提升召回率（Recall）。
3.  **小物件優化：** 雖然 640x640 解析度表現尚可，但針對極微小的主動脈瓣鈣化點，未來可嘗試使用 SAHI（Slicing Aided Hyper Inference）切片推論技術，或將輸入解析度提升至 1280x1280，以捕捉更細微的病徵。

總結而言，本研究成功驗證了 YOLOv11 應用於主動脈瓣偵測的可行性，並透過針對性的資料處理與參數優化，建立了一套高精度的自動化偵測流程。

## 肆、使用的外部資源與參考文獻

本報告及專案開發過程中，使用了以下開源資源與參考文獻，並嚴格遵守相關授權規範與中華民國著作權法。

1.  **Ultralytics YOLOv11**
    *   來源：https://github.com/ultralytics/ultralytics
    *   說明：本專案之核心物件偵測演算法架構。使用 AGPL-3.0 授權。
2.  **PyTorch Deep Learning Framework**
    *   來源：https://pytorch.org/
    *   說明：用於建構神經網路之底層框架。
3.  **OpenCV (Open Source Computer Vision Library)**
    *   來源：https://opencv.org/
    *   說明：用於影像讀取、前處理及幾何變換。
4.  **Jocher, G., Chaurasia, A., & Qiu, J. (2023).** *YOLO by Ultralytics*.
    *   說明：參考其官方文檔進行超參數設定與模型架構理解。
5.  **Loshchilov, I., & Hutter, F. (2017).** *Decoupled Weight Decay Regularization*. arXiv preprint arXiv:1711.05101.
    *   說明：參考 AdamW 優化器之理論基礎。

*(本報告內容由 TEAM_8944 成員撰寫，部分段落輔以生成式 AI 工具潤飾語句通順度，所有實驗數據與程式邏輯皆為團隊實作之結果。)*
